{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 초모수와 모델 검증\n",
    "\n",
    "지도학습 모델을 적용하는 기본 단계는 아래와 같다.\n",
    "\n",
    "1. 모델 클래스 선택\n",
    "2. 모델 초모수 선택\n",
    "3. 모델을 훈련 데이터에 적합\n",
    "4. 모델을 사용해 새 데이터에 대한 레이블 예측\n",
    "\n",
    "처음 두 단계인 모델 선택과 초모수 선택이 아마 이 도구와 기법을 효과적으로 사용하는 데 가장 중요한 부분일 것이다. 정보에 입각한 선택을 하려면 선택한 모델과 초모수가 데이터에 잘 적합되는지 검증할 방법이 필요하다. 간단한 것처럼 들리지만 효과적인 검증을 위해서 피해야 할 몇가지 주의 사항이 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 모델 검증에 대한 고려 사항\n",
    "\n",
    "이론적으로 모델 검증은 매우 단순하다. 모델과 모델의 초모수를 선택한 후, 훈련 데이터 일부에 이를 적용하고 예측값을 알려진 값과 비교해서 이 모델이 얼마나 효과적인지 추정할 수 있다.\n",
    "\n",
    "먼저 순진한 방식으로 모델을 검증하면 왜 실패하는지 보여주고좀 더 견고한 모델 평가를 위해 검정 표본과 교차 검증을 사용해보자.\n",
    "\n",
    "### 잘못된 방식의 모델 검증\n",
    "\n",
    "~ 생략 ~\n",
    "\n",
    "### 올바른 방식의 모델 검증 : 검증 표본\n",
    "\n",
    "모델의 성능을 제대로 알려면 검증 표본(holdout set)을 사용하면 된다.\n",
    "\n",
    "즉, 모델의 훈련 데이터에서 데이터의 일부를 빼내 그것을 모델 성능을 확인하는 검정 표본으로 사용하는 것이다. 이 분리 작업에는 scikit-learn의 `train_test_split` 유틸리티를 사용하면 된다.\n",
    "\n",
    "### 교차 검증을 통한 모델 검증\n",
    "\n",
    "모델 검증에 검정 표본을 사용할 때의 한 가지 단점은 모델을 훈련시킬 데이터의 일부를 잃게된다는 것이다. 앞의 경우에 데이터 세트의 반은 모델을 훈련시키는데 기여하지 못한다. 이는 특히 초기 훈련 데이터가 작은 경우에는 적절하지 않은 방법으로, 문제가 발생할 수 있다.\n",
    "\n",
    "이 문제를 해결하기 위한 한가지 방법은 **교차 검증**(cross-validation)을 사용하는 것이다. 즉, 데이터의 각 하위 집합이 훈련 자료와 검증 자료로 사용되도록 일련의 적합을 수행하는 것이다.\n",
    "\n",
    "여기서도 마찬가지로 사이킷런의 `cross_val_score`를 사용하면 간결하게 수행할 수 있다.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "cross_val_score(model, X, y, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터의 하위 집합별로 검증을 반복함으로써 알고리즘 성능에 대해 더 나은 판단을 할 수 있다.\n",
    "\n",
    "사이킷런은 특정 상황에 유용한 수많은 교차 검증 방식을 구현하고 있다. 이 방식은 cross_validation 모듀ㅜㄹ의 반복자를 통해 구현된다. 예를 들어, 데이터 점의 개수와 같은 수만큼 반복하는 교차 검증을 하는 극단적인 경우를 원할수도 있다. 다시 말하면 검증을 시행할 때마다 한 점을 제외한 모든 점에 대해 훈련하는 것이다. 이러한 유형의 교차 검증을 **단일 관측치 제거 방식**(leave-one-out) 교차검증이라고 한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.cross_validation import LeaveOneOut\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=LeaveOneOut(len(X)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 최적의 모델 선택하기\n",
    "\n",
    "검증과 교차 검증의 기본 내용을 살펴봤으니 이제 모델과 초모수 선택과 관련해 더 깊이있게 알아보자. 이 이슈는 실제 머신러닝에서 가장 중요한 측면에 속하지만, 머신러닝 입문서에서는 그 정보를 건너 뛰는 경우가 자주 있다.\n",
    "\n",
    "다음과 같은 질문을 하는 것이 가장 중요하다. *모델의 성능이 저조하다면 어떻게 개선할 것인가?* 이 문제를 해결하는 몇가지 답이 있다.\n",
    "\n",
    "- 더 복잡하거나 더 유연한 모델 사용\n",
    "- 덜 복잡하거나 덜 유연한 모델 사용\n",
    "- 더 많은 훈련 표본 수집\n",
    "- 각 표본에 특징을 추가하기 위해 더 많은 데이터 수집\n",
    "\n",
    "이 질문에 대한 답은 종종 직관에 어긋난다. 특히 더 복잡한 모델을 사용해서 결과가 악화되는 경우도 있고 더 많은 훈련 표본을 추가해도 결과가 개선되지 않을 수 있다. 어느 단계가 모델을 개선할 수 있을지 결정하는 능력이 성공한 머신러닝 실무자와 실패한 실무자를 구분짓는다.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 편향 - 분산 트레이드오프\n",
    "\n",
    "근본적으로 '최고의 모델'을 선택하는 것은 편향과 분산 사이의 트레이드 오프에서 가장 효율적인 점을 찾는 것이다.\n",
    "\n",
    "- 고편향 모델의 경우 검정 표본에서의 모델 성능이 훈련 표본에서의 성능과 유사하다.\n",
    "- 고분산 모델의 경우 검정 표본에서의 모델 성능이 훈련 표본에서의 성능보다 훨씬 더 떨어진다.\n",
    "\n",
    "고편향 : 모델의 복잡도가 낮은 경우 / 고분산 : 모델의 복잡도가 너무 높은 경우\n",
    "\n",
    "검증 곡선 : 모델 복잡도와 훈련 점수, 검증 점수 사이의 관계 도식 (validation curve)\n",
    "\n",
    "모델 복잡도를 조정하는 도구는 모델에 따라 다양하다. \n",
    "\n",
    "## 학습 곡선\n",
    "\n",
    "모델의 복잡도를 결정하는데 중요한 요소중 하나는 최적의 모델은 일반적으로 훈련 데이터의 규모에 의해 의존한다는 사실이다.\n",
    "\n",
    "- 훈련 표본의 개수가 커질수록 특정 점수로 수렴한다.\n",
    "- 이미 충분한 데이터를 가지고 있다면 훈련 데이터를 더 늘리는 것은 도움이 되지 않는다"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 실제 검증 : 그리드 검색\n",
    "\n",
    "지금까지 편향과 분산 사이의 트레이드오프와 이 트레이드오프가 모델 복잡도와 훈련 집합 크기에 대해 어떤 종속성을 가지는지 이해를 돕고자 설명했다. 실제 모델에는 일반적으로 복잡도를 제어할 수 있는 수단이 하나 이상 있어 검증 곡선과 학습 곡선 플롯이 직선에서 다차원 표면으로 변경된다. 그러한 경우에는 시각화하기가 매우 어려우므로 검증 점수를 최대화하는 특정 모델을 찾는 것이 낫다.\n",
    "\n",
    "사이킷런은 이 작업을 수행하는 자동화 도구로 `grid_search` 모듈을 제공한다. 관련하여 최적의 다항식 모델을 구하기 위해 그리드 검색을 사용하는 예제를 살펴보자. 여기서는 모델 특징을 담은 3차원 그리드를 탐색할 것이다. 이 그리드는 다항식 차수와 절편에 적합시킬지 말지 알려주는 플래그와 문제를 정규화할 것인지 아닌지 알려주는 플래그로 구성된다. 이것은 사이킷런의 `GridSearchCV` 메타 추정기를 사용해 설정할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'polynomialfeatures__degree' : np.arange(21),\n",
    "    'linearregression__fit_intercept' : [True, False],\n",
    "    'linearregression__normalize' : [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(PolynomicalRegression(), param_grid, cv=7)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "일반 추정기와 마찬가지로 이 메타 추정기도 아직 어떤 데이터에도 적용되지 않았다. `fit()` 메서드를 호출하면 모델을 각 그리드 점에 적합시키면서 계속 점수를 기록할 것이다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid.fit(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래와 같이 사용하면 최적의 모델을 사용하고 이전 코드를 사용해 데이터에 적합하는 것을 보여줄 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = grid.best_estimator_\n",
    "y_test = model.fit(X, y).predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}