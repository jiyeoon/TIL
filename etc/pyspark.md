# 스파크 이해하기

아파치 스파크는 마태자하리아가 UC 버클리에서 박사과정 논문의 일부로 개발한 강력한 오픈소스 처리 엔진이다. 스파크는 오픈소스 분산 쿼리 및 처리 엔진으로, 유연성과 맵리듀스에 대한 확장성을 훨씬 빠른 속도로 제공한다. 데이터가 메모리에 저장되어있을 경우에는 하둡보다 100배 빠르며, 디스크에 저장되어 있을 때에는 10배 빠르다.

스파크는 데이터를 읽고, 변형하고, 합계를 낼 수 있으며 복잡한 통계 모델들을 쉽게 학습하고 배포할 수 있다. 스파크 API는 자바, 스칼라, 파이썬, R, SQL을 이용해 접근할 수 있다. 어플리케이션을 빌드하는데 쓰일수도 있고, 여러 어플리케이션을 라이브러리로 묶어서 클러스터에 배포할수도 있으며, 파이썬 노트북을 통해 대화식으로 빠른 분석을 수행할 수 있다.

## 스파크 잡과 API

### 실행 프로세스

모든 스파크 애플리케이션은 여러 개의 잡을 가질 수 있는 하나의 드라이버 프로세스를 마스터 노드에서 실행한다. 드라이버 프로세스는 아래 그림처럼 실행 프로세스들을 컨트롤한다. 여러 태스크를 포함하고 있는 실행 프로세스들은 여러 개의 워커 노드로 태스크를 분산시킨다.

![img](https://dthumb-phinf.pstatic.net/?src=%22https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F990DA73B5AA356CE0B%22&type=w2)

드라이버 프로세스는 태스크 프로세스의 개수와 구성을 결정한다. 태스크 프로세스는 하나의 잡 그래프에 기반해 실행 노드에 의해 컨트롤된다. 모든 워커 노드는 서로 다른 잡으로부터 받은 태스크를 실행할 수 있다. 

스파크 잡에서의 객체 의존성은 **비순환 방향성 그래프(DAG)** 형태로 표현할 수 있다. 비순환 방향성 그래프는 스파크 UI상에서 아래와 같이 생성된다. 이 그래프를 기반으로 스파크는 스케줄링과 태스크 실행을 최적화할 수 있다. 

![img](https://dthumb-phinf.pstatic.net/?src=%22https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F990C0D435AA354E40C%22&type=w2)

### RDD

스파크는 **RDD(Resilient Distributed Datasets, 탄력적 분산 데이터셋)**이라고 불리는 이뮤터블(immutable) 자바 가상 머신(JVM) 객체들의 집합으로 만들어졌다. 이 객체들은 잡들이 매우 빠르게 연산할 수 있도록 *메모리상에서* 캐시되고 저장되고 계산된다. 이러한 스키마는 하둡과 같은 다른 전형적인 분산 처리 시스템과 비교해 빠른 연산을 가능하게 한다.

또한 RDD는 `map()`, `reduce()`, `filter()`와 같은 트랜스포메이션(transformation)을 제공하며, 다양한 연산을 수행하기 위해 하둡 플랫폼의 유연성과 확장성을 유지한다. RDD는 **병렬로 데이터에 트랜스포메이션을 적용하고 기록**하는데, 이는 속도와 내구성을 향상시킨다. RDD는 트랜스포메이션별로 **데이터의 흐름(data lineage)**를 제공한다. 이로 인해 RDD는 데이터 유실을 막을 수 있으며, RDD 일부의 파티션이 없어지더라도 추가적인 데이터 복구를 하지 않고 유실된 파티션을 재생산해낼 수 있는 충분한 데이터를 가지고 있다.

RDD에서 병렬 연산은 포인터를 새로운 RDD에 리턴하는 **트랜스포메이션(transformation)**과 연산 후에 값을 리턴하는 **액션(action)** 이렇게 두종류가 있다. 

RDD 트랜스포메이션은 *연산을 즉시 하지 않는다*는 점에서 **게으른 연산**이다. 트렌스포메이션은 액션이 실행되고 결과가 드라이버에 리턴되어야 할때만 수행된다. 실행을 지연시키려면 성능 측면에서 더욱 정교화된 쿼리를 수행할 수 있다. 최적화는 아파치 스파크 DAG 스케줄러(스테이지를 이용해 변형하는 스테이지 기반의 스케줄러)에서 시작된다. RDD는 트랜스포메이션과 액션이 분리되어 DAG 스케줄러의 경우 최적화를 쿼리상에서 수행할 수 있으며, 또한 데이터를 섞는 것 같은 상당한 리소스가 소모되는 작업을 피할 수 있다. 

### 데이터프레임

RDD와 같이 데이터프레임은 클러스터상의 여러 노드에 분산된 이뮤터블 데이터 집합이다. 그러나 RDD와는 달리 데이터프레임의 데이터는 칼럼명으로 이루어져 있다. (pandas의 데이터프레임과 비슷한 개념)

데이터프레임은 큰 데이터셋을 쉽게 처리하기위해 디자인되었다. 데이터프레임으로 데이터의 구조를 공식화할 수 있으며, 상위 계층에 대한 추상화도 가능하다. 이러한 점에서 데이터프레임은 관계형 데이터베이스의 테이블과 비슷하다. 데이터프레임은 부산 데이터를 다루기 위해 그리고 전문 데이터 엔지니어 뿐만 아니라 더 많은 사람들이 스파크에 접근할 수 있도록 하기위해 각 주제별 API들을 제공한다.

스파크 엔진은 최초에 논리적인 실행 계획을 작성하고 물리적 플랜에 의해 생성된 코드를 실행한다. 이 물리적 플랜은 비용 옵티마이저(cost optimizer)에 의해 결정된다. 이는 데이터프레임의 가장 큰 장점 중 하나다. 자바나 스칼라에 비교해 파이썬에서는 상당히 느린 RDD와 다르게 데이터프레임은 모든 언어에 균일한 성능을 나타낸다.

### 데이터셋

스파크 데이터셋의 목적은 사용자가 도메인 객체에서 트랜스포메이션을 쉽게 표현할 수 있는 API를 제공하고, 또한 견고한 스파크 SQL 실행 엔진의 성능과 장점을 제공하는 것이다. 현재는 자바와 스칼라에서만 데이터셋이 사용 가능하다.

### 카탈리스트 옵티마이저

스파크 SQL은 SQL쿼리와 데이터프레임 API를 모두 강화시키기 때문에 아파치 스파크에서 가장 기술적으로 발전되고 디자인된 구성 요소 중 하나다. 스파크 SQL 코어에는 카탈리스트 옵티마이저가 있다. 이 옵티마이저는 함수 프로그래밍 구조에 기반하고 있으며 두 가지 목적을 위해 디자인되었다. 하나는 새로운 최적화 기술과 스파크 SQL 피처를 쉽게 추가하기 위함이고 다른 하나는 외부 개발자들이 옵티마이저를 확장시킬 수 있도록 하기 위함이다.




## 스파크의 전역 범위 vs. 지역 범위

스파크에서 병렬처리를할 때 두가지 모드로 동작할 수 있다. 첫째는 클러스터 모드이며 두번째는 로컬 모드이다. 스파크가 로컬 모드로 동작할때는 파이썬을 실행시키는 것과 다르지 않을 수 있다.

골치 아픈 일이 많이 생기는 것은 바로 클러스터 모드인데, 먼저 어떻게 스파크가 클러스터에서 job 을 실행시키는지 이해할 필요가 있다.

클러스터 모드에서 잡이 실행되면, 그 잡은 드라이버 노드 (또는 마스터 노드)로 보내진다.

드라이버 노드는 잡을 위해 DAG를 생성하고 어떤 실행 노드(또는 워커 노드)가 특정 태스크를 실행할지 결정한다. 그리고 드라이버는 각 태스크를 마칠 준비를 한 후 워커 노드가 각자의 태스크를 수행하고 작업을 마치면 그 결과를 드라이버 노드에 리턴하도록 한다. 

이 변수와 함수는 내부적으로 실행 노드의 문맥사에서 정적이다. 즉, 각자의 실행 노드가 드라이버 노드에서 사용되는 변수와 함수를 복사해 사용한다. 태스크를 실행할 때, 실행노드가 이 변수나 함수를 수정할 경우 다른 실행 노드들의 변수나 함수에는 영향을 주지 않는다는 것이다. 이로 인해 런타임 버그나 몇몇 이상행위를 유발할 수 있는데, 보통 이러한 오류들은 굉장히 추적하기가 힘들다.
