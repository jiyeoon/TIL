{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobert_tokenizer\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /private/var/folders/qh/y2br1r8j2ps17bw3qkqmxjrh0000gn/T/pip-install-vkxw5wuh/kobert-tokenizer_3d4469269c2d432a887b483bcf1cf038\n",
      "Building wheels for collected packages: kobert-tokenizer\n",
      "  Building wheel for kobert-tokenizer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kobert-tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4649 sha256=9eba7119ec890c34c513af95237eb693d39f662c40aead1c881aa07fb334be50\n",
      "  Stored in directory: /private/var/folders/qh/y2br1r8j2ps17bw3qkqmxjrh0000gn/T/pip-ephem-wheel-cache-_nbfaklp/wheels/10/b4/d9/cb627bbfaefa266657b0b4e8127f7bf96d27376fa1a23897b4\n",
      "Successfully built kobert-tokenizer\n",
      "Installing collected packages: kobert-tokenizer\n",
      "Successfully installed kobert-tokenizer-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /private/var/folders/qh/y2br1r8j2ps17bw3qkqmxjrh0000gn/T/pip-req-build-jsmv1bud\n",
      "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from kobert==0.2.3) (1.9.0)\n",
      "Collecting onnxruntime<=1.8.0,==1.8.0\n",
      "  Downloading onnxruntime-1.8.0-cp37-cp37m-macosx_10_12_x86_64.whl (5.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.0 MB 185 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /Users/a1101497/.local/lib/python3.7/site-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (4.21.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.19.2)\n",
      "Collecting boto3<=1.15.18\n",
      "  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.19.0,>=1.18.18\n",
      "  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.1)\n",
      "Collecting gluonnlp<=0.10.0,>=0.6.0\n",
      "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "\u001b[K     |████████████████████████████████| 344 kB 25.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (20.8)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting mxnet<=1.7.0.post2,>=1.4.0\n",
      "  Downloading mxnet-1.7.0.post2-py3-none-macosx_10_13_x86_64.whl (30.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.2 MB 1.5 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.25.1)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.9.24)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 5.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (3.7.4.3)\n",
      "Collecting transformers<=4.8.1,>=4.8.1\n",
      "  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.55.1)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Using cached huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp37-cp37m-macosx_10_9_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 26.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.26,>=1.20\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cython\n",
      "  Using cached Cython-0.29.33-py2.py3-none-any.whl (987 kB)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.4.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/a1101497/opt/anaconda3/envs/study/lib/python3.7/site-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.0.0)\n",
      "Building wheels for collected packages: kobert, gluonnlp, sacremoses\n",
      "  Building wheel for kobert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15697 sha256=5669d977aaad3745f6532ca33ed8df43e9ae09e6126e164544d65913f719c5e9\n",
      "  Stored in directory: /private/var/folders/qh/y2br1r8j2ps17bw3qkqmxjrh0000gn/T/pip-ephem-wheel-cache-__t5iaco/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-macosx_10_9_x86_64.whl size=461178 sha256=3fff9cf061f4feb6f15a1cdf2f1fddc5ae529c82508c9057668b98605a8ee765\n",
      "  Stored in directory: /Users/a1101497/Library/Caches/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=9596c84b234c062af2da3083b87dfc54d452f74b0d95740e545dc9a1080c7c7a\n",
      "  Stored in directory: /Users/a1101497/Library/Caches/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built kobert gluonnlp sacremoses\n",
      "Installing collected packages: urllib3, jmespath, regex, packaging, filelock, botocore, tokenizers, sacremoses, s3transfer, huggingface-hub, graphviz, cython, transformers, sentencepiece, onnxruntime, mxnet, gluonnlp, boto3, kobert\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.2\n",
      "    Uninstalling urllib3-1.26.2:\n",
      "      Successfully uninstalled urllib3-1.26.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.8\n",
      "    Uninstalling packaging-20.8:\n",
      "      Successfully uninstalled packaging-20.8\n",
      "  Attempting uninstall: graphviz\n",
      "    Found existing installation: graphviz 0.16\n",
      "    Uninstalling graphviz-0.16:\n",
      "      Successfully uninstalled graphviz-0.16\n",
      "Successfully installed boto3-1.15.18 botocore-1.18.18 cython-0.29.33 filelock-3.9.0 gluonnlp-0.10.0 graphviz-0.8.4 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 packaging-23.0 regex-2022.10.31 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.8.1 urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ctlg_nm</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>tokenized_ctlg_nm</th>\n",
       "      <th>tokenized_model_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>30대 호텔 강습 치마 중년 빅사이즈 스커트 수영장 여성래쉬가드 긴팔 60대</td>\n",
       "      <td>서핑 자외선 래쉬가드수영복 긴팔 프린트 수영복</td>\n",
       "      <td>30대 호텔 강습 치마 중년 빅 사이즈 스커트 수영장 여성 래쉬가드 긴팔 60대</td>\n",
       "      <td>서핑 자외선 래쉬가드 수영복 긴팔 프린트 수영복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1pcs 골프 부 클램프 블랙 고무 플라스틱 클럽 그립 바이스 교체 도구 연습</td>\n",
       "      <td>베스트골프그립 플라스틱 골프 연습 클럽 그립 바이스 클램프 교체 도구 웨지 클램프</td>\n",
       "      <td>1pcs 골프 부 클램프 블랙 고무 플라스틱 클럽 그립 바이스 교체 도구 연습</td>\n",
       "      <td>베스트 골프 그립 플라스틱 골프 연습 클럽 그립 바이스 클램프 교체 도구 웨지 클램프</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>바다생물 모형 피규어 유치원 교구</td>\n",
       "      <td>바다생물 모형 피규어 유치원 교구 동물피규어 조형물</td>\n",
       "      <td>바다 생물 모형 피규어 유치원 교구</td>\n",
       "      <td>바다 생물 모형 피규어 유치원 교구 동물 피규어 조형물</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>꼭지물병 3호 15L 스텐물통 빨대물병 스포츠물병</td>\n",
       "      <td>보성 꼭지 물병 3호 1 5L</td>\n",
       "      <td>꼭지 물병 3호 15l 스텐 물통 빨대 물병 스포츠 물병</td>\n",
       "      <td>보성 꼭지 물병 3호 1 5l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>Darer 유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서</td>\n",
       "      <td>유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서</td>\n",
       "      <td>darer 유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서</td>\n",
       "      <td>유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>11202401311 여성 스트랩 샌들</td>\n",
       "      <td>미소페 여성 스트랩 샌들 11202401311</td>\n",
       "      <td>11202401311 여성 스트랩 샌들</td>\n",
       "      <td>미소페 여성 스트랩 샌들 11202401311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>OAKLEY HOLBROOK WOODGRAIN W PRIZM DEEP WATER P...</td>\n",
       "      <td>오클리 HOLBROOK WOODGRAIN w PRIZM DEEP WATER POLA...</td>\n",
       "      <td>oakley holbrook woodgrain w prizm deep water p...</td>\n",
       "      <td>오클리 holbrook woodgrain w prizm deep water pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>미터 나사 탭 M16 M16X2 M16X1 M16X075 M16X05 LH 왼손 스...</td>\n",
       "      <td>미터 나사 탭 M16 LH 왼손 스트레이트 플루트 5 25 75 M16X175</td>\n",
       "      <td>미터 나사 탭 m16 m16x2 m16x1 m16x075 m16x05 lh 왼손 스...</td>\n",
       "      <td>미터 나사 탭 m16 lh 왼손 스트레이트 플루트 5 25 75 m16x175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>33JUSP05 22680299 남성</td>\n",
       "      <td>22FW 저스트 돈 캐주얼 바지 33JUSP05 22680299</td>\n",
       "      <td>33jusp05 22680299 남성</td>\n",
       "      <td>22 fw 저스트 돈 캐주얼 바지 33jusp05 22680299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>925실버 데일리 하트 C링 후크귀걸이</td>\n",
       "      <td>925실버 데일리 하트 C링 후크귀걸이-쿼먼트</td>\n",
       "      <td>925 실버 데일리 하트 c 링 후크 귀걸이</td>\n",
       "      <td>925 실버 데일리 하트 c 링 후크 귀걸이 쿼먼트</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                            ctlg_nm  \\\n",
       "71          71         30대 호텔 강습 치마 중년 빅사이즈 스커트 수영장 여성래쉬가드 긴팔 60대   \n",
       "0            0        1pcs 골프 부 클램프 블랙 고무 플라스틱 클럽 그립 바이스 교체 도구 연습   \n",
       "16          16                                 바다생물 모형 피규어 유치원 교구   \n",
       "44          44                        꼭지물병 3호 15L 스텐물통 빨대물병 스포츠물병   \n",
       "90          90      Darer 유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서   \n",
       "32          32                              11202401311 여성 스트랩 샌들   \n",
       "61          61  OAKLEY HOLBROOK WOODGRAIN W PRIZM DEEP WATER P...   \n",
       "34          34  미터 나사 탭 M16 M16X2 M16X1 M16X075 M16X05 LH 왼손 스...   \n",
       "94          94                               33JUSP05 22680299 남성   \n",
       "1            1                              925실버 데일리 하트 C링 후크귀걸이   \n",
       "\n",
       "                                             model_nm  \\\n",
       "71                          서핑 자외선 래쉬가드수영복 긴팔 프린트 수영복   \n",
       "0       베스트골프그립 플라스틱 골프 연습 클럽 그립 바이스 클램프 교체 도구 웨지 클램프   \n",
       "16                       바다생물 모형 피규어 유치원 교구 동물피규어 조형물   \n",
       "44                                   보성 꼭지 물병 3호 1 5L   \n",
       "90            유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서   \n",
       "32                          미소페 여성 스트랩 샌들 11202401311   \n",
       "61  오클리 HOLBROOK WOODGRAIN w PRIZM DEEP WATER POLA...   \n",
       "34        미터 나사 탭 M16 LH 왼손 스트레이트 플루트 5 25 75 M16X175   \n",
       "94                22FW 저스트 돈 캐주얼 바지 33JUSP05 22680299   \n",
       "1                           925실버 데일리 하트 C링 후크귀걸이-쿼먼트   \n",
       "\n",
       "                                    tokenized_ctlg_nm  \\\n",
       "71       30대 호텔 강습 치마 중년 빅 사이즈 스커트 수영장 여성 래쉬가드 긴팔 60대   \n",
       "0         1pcs 골프 부 클램프 블랙 고무 플라스틱 클럽 그립 바이스 교체 도구 연습   \n",
       "16                                바다 생물 모형 피규어 유치원 교구   \n",
       "44                    꼭지 물병 3호 15l 스텐 물통 빨대 물병 스포츠 물병   \n",
       "90      darer 유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서   \n",
       "32                              11202401311 여성 스트랩 샌들   \n",
       "61  oakley holbrook woodgrain w prizm deep water p...   \n",
       "34  미터 나사 탭 m16 m16x2 m16x1 m16x075 m16x05 lh 왼손 스...   \n",
       "94                               33jusp05 22680299 남성   \n",
       "1                            925 실버 데일리 하트 c 링 후크 귀걸이   \n",
       "\n",
       "                                   tokenized_model_nm  \n",
       "71                         서핑 자외선 래쉬가드 수영복 긴팔 프린트 수영복  \n",
       "0     베스트 골프 그립 플라스틱 골프 연습 클럽 그립 바이스 클램프 교체 도구 웨지 클램프  \n",
       "16                     바다 생물 모형 피규어 유치원 교구 동물 피규어 조형물  \n",
       "44                                   보성 꼭지 물병 3호 1 5l  \n",
       "90            유리 보관 병 쌓을 수 시리얼 용기 세트 2단 밀폐 주방 음식 디스펜서  \n",
       "32                          미소페 여성 스트랩 샌들 11202401311  \n",
       "61  오클리 holbrook woodgrain w prizm deep water pola...  \n",
       "34        미터 나사 탭 m16 lh 왼손 스트레이트 플루트 5 25 75 m16x175  \n",
       "94               22 fw 저스트 돈 캐주얼 바지 33jusp05 22680299  \n",
       "1                        925 실버 데일리 하트 c 링 후크 귀걸이 쿼먼트  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 371k/371k [00:00<00:00, 483kB/s]  \n",
      "Downloading: 100%|██████████| 244/244 [00:00<00:00, 117kB/s]\n",
      "Downloading: 100%|██████████| 432/432 [00:00<00:00, 204kB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁9',\n",
       " '25',\n",
       " '▁실',\n",
       " '버',\n",
       " '▁',\n",
       " '데일리',\n",
       " '▁하',\n",
       " '트',\n",
       " '▁c',\n",
       " '▁',\n",
       " '링',\n",
       " '▁후',\n",
       " '크',\n",
       " '▁귀',\n",
       " '걸',\n",
       " '이']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._tokenize(df['tokenized_ctlg_nm'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1pcs 골프 부 클램프 블랙 고무 플라스틱 클럽 그립 바이스 교체 도구 연습'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_ctlg_nm'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 1 (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e9fa94e2d8fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'롸'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'리'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m out = model(input_ids=torch.tensor(inputs['input_ids']), \n\u001b[0m\u001b[1;32m      9\u001b[0m             attention_mask=torch.tensor(inputs['attention_mask']))\n\u001b[1;32m     10\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 1 (got 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "text = df['tokenized_ctlg_nm'].iloc[0]\n",
    "\n",
    "inputs = tokenizer.batch_encode_plus([text])\n",
    "out = model(input_ids=torch.tensor(inputs['input_ids']), \n",
    "            attention_mask=torch.tensor(inputs['attention_mask']))\n",
    "out.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.batch_encode_plus(df['tokenized_ctlg_nm'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 30 at dim 1 (got 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d236edeb9377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# inputs = tokenizer.batch_encode_plus([text])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m out = model(input_ids=torch.tensor(inputs['input_ids']), \n\u001b[0m\u001b[1;32m      5\u001b[0m             attention_mask=torch.tensor(inputs['attention_mask']))\n\u001b[1;32m      6\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 30 at dim 1 (got 18)"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.batch_encode_plus(df['tokenized_ctlg_nm'].to_list())\n",
    "# inputs = tokenizer.batch_encode_plus([text])\n",
    "\n",
    "out = model(input_ids=torch.tensor(inputs['input_ids']), \n",
    "            attention_mask=torch.tensor(inputs['attention_mask']))\n",
    "out.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.6838e-03, -2.1266e-02, -2.8882e-01,  4.2807e-02, -9.8462e-01,\n",
       "         9.9541e-01,  5.7740e-02,  5.3906e-02, -6.3186e-02, -1.7581e-02,\n",
       "        -6.9305e-01,  1.4925e-02, -6.6196e-03,  3.3149e-02, -1.6161e-02,\n",
       "         8.2862e-01, -9.9426e-01, -2.5871e-02, -1.0755e-02,  5.5260e-02,\n",
       "        -2.6951e-02, -3.9756e-02,  3.6781e-02,  7.9446e-01,  3.6700e-02,\n",
       "         8.8500e-01, -9.8399e-01,  9.7341e-02, -9.9631e-01, -1.0970e-02,\n",
       "         6.1351e-01,  9.1645e-01, -4.1462e-03, -1.9670e-02, -3.9502e-01,\n",
       "         4.4198e-01,  9.6813e-03,  4.2857e-03, -9.8950e-01, -2.4084e-02,\n",
       "        -5.0355e-02, -9.1750e-02,  1.7282e-02,  9.9487e-01, -9.9999e-01,\n",
       "        -2.5988e-02,  6.9342e-01,  3.9692e-02, -1.0000e+00,  9.9964e-01,\n",
       "         4.9495e-02, -1.0000e+00, -9.9991e-01,  1.6584e-02, -2.1688e-03,\n",
       "        -9.8055e-01,  1.9569e-03,  8.8364e-01,  2.8858e-02, -7.5225e-03,\n",
       "        -5.6879e-02,  2.3269e-02,  9.9753e-01, -9.9708e-01, -4.0557e-02,\n",
       "        -1.8147e-03, -4.2136e-02,  1.6085e-02, -4.4851e-04, -1.5477e-02,\n",
       "         9.9864e-01, -8.6867e-02, -2.3927e-02, -1.3364e-02, -8.4729e-01,\n",
       "        -5.0834e-02, -7.1744e-02, -2.4346e-02,  6.2416e-02,  1.9265e-02,\n",
       "         8.9387e-02, -9.4586e-01, -9.2087e-01,  8.0452e-01, -6.1757e-02,\n",
       "        -8.3359e-02, -2.6531e-02, -1.8085e-02,  9.9811e-01, -9.1112e-01,\n",
       "        -4.8365e-02, -7.5190e-02,  7.6506e-02,  4.4967e-02, -9.7460e-01,\n",
       "         1.1305e-02, -6.1068e-02,  3.3727e-02,  9.6330e-03,  1.3767e-01,\n",
       "        -5.0546e-02, -4.5969e-02,  3.7932e-02,  4.1921e-02, -9.8776e-01,\n",
       "        -6.9906e-03,  2.2015e-02, -3.3012e-02, -6.2456e-03,  4.1349e-02,\n",
       "         1.8647e-03, -2.8022e-02,  6.8843e-01,  2.5017e-03, -3.8893e-01,\n",
       "         2.1196e-02, -3.4802e-02, -7.6958e-03,  7.6693e-02,  5.4254e-02,\n",
       "         1.4472e-02,  2.0905e-02, -9.9593e-01,  9.9497e-01, -1.0000e+00,\n",
       "         1.3693e-02, -4.3533e-01,  3.3922e-02, -2.8604e-02, -2.1372e-02,\n",
       "        -3.9815e-02, -2.2036e-02, -4.3392e-03, -2.5288e-02, -8.4101e-03,\n",
       "         3.8449e-02, -3.9287e-01, -1.0622e-02,  1.9811e-02, -4.1306e-02,\n",
       "        -2.8319e-03,  1.1782e-02,  9.1315e-01,  7.3155e-01,  4.4910e-02,\n",
       "         4.0688e-02, -2.8363e-02, -1.0213e-02,  6.9797e-02, -3.1021e-02,\n",
       "        -9.9737e-01,  1.7912e-02, -8.8015e-01,  4.7866e-02,  8.4855e-03,\n",
       "         2.6486e-02,  3.7980e-03, -4.4767e-02, -8.7456e-02, -9.8930e-01,\n",
       "        -6.2530e-02,  1.2244e-02,  1.1920e-02,  9.9983e-01,  4.9045e-02,\n",
       "         4.2946e-02,  1.8714e-02,  8.0714e-01, -5.0987e-02,  2.7460e-02,\n",
       "        -1.4469e-02,  3.2286e-02, -9.9973e-01, -4.0194e-01, -2.3799e-02,\n",
       "         1.0000e+00, -2.7672e-04, -9.8234e-01,  9.3298e-03, -1.1886e-02,\n",
       "         2.0136e-02,  9.9873e-01,  9.4312e-02, -1.0000e+00,  1.4831e-02,\n",
       "        -3.4805e-02,  2.4542e-02,  8.4516e-03,  7.3244e-02,  2.4342e-01,\n",
       "        -9.9880e-02,  3.6167e-03, -4.8211e-01,  4.6621e-03, -1.3311e-01,\n",
       "        -1.2943e-02,  4.8838e-01,  7.0464e-03,  2.3814e-03,  6.9542e-02,\n",
       "        -1.0715e-02,  8.9364e-01,  5.8145e-02,  1.8772e-02,  9.9631e-01,\n",
       "         2.2251e-03, -1.7242e-02,  9.8246e-03, -7.4152e-01,  8.5905e-01,\n",
       "         6.6074e-03,  3.6310e-02,  9.9484e-01,  9.9006e-01,  8.6783e-02,\n",
       "         7.6973e-03,  7.4331e-03,  8.7180e-01,  9.9394e-01, -9.9477e-01,\n",
       "        -9.5811e-01, -2.2431e-02,  2.9647e-02, -3.5437e-02,  4.9486e-02,\n",
       "        -2.1041e-01,  8.9138e-01, -9.9638e-01,  1.0446e-01, -2.4091e-02,\n",
       "        -9.9974e-01,  1.8030e-02,  6.3026e-02, -4.4068e-01,  6.6126e-01,\n",
       "        -4.3193e-01,  9.6075e-01,  1.5061e-02,  5.5829e-04,  2.7741e-03,\n",
       "         9.3658e-01,  3.7039e-02,  9.9244e-01, -4.3035e-03,  9.8540e-01,\n",
       "        -4.8409e-02, -5.9966e-02,  9.9385e-01,  1.2325e-03,  9.9880e-01,\n",
       "        -5.7532e-02, -2.4201e-02,  1.1342e-02,  7.9180e-02,  1.5063e-02,\n",
       "        -3.4956e-02,  9.9437e-01, -3.2644e-02,  9.9764e-01, -9.5559e-01,\n",
       "        -1.1388e-02, -3.4968e-03, -4.9110e-02,  5.8138e-03,  5.0235e-01,\n",
       "         2.9886e-02,  3.7568e-02, -9.4267e-01, -9.2326e-01,  1.0649e-02,\n",
       "        -2.0163e-03, -5.3205e-03,  8.0983e-03,  8.5229e-01,  9.5132e-01,\n",
       "        -9.9558e-01, -1.1426e-02, -3.3540e-02, -1.4432e-02,  2.0912e-02,\n",
       "        -2.8545e-02,  4.4992e-01, -9.9767e-01, -3.2232e-02,  3.7280e-02,\n",
       "        -1.2422e-02,  1.8119e-02, -1.9475e-03, -1.7418e-02,  2.8995e-02,\n",
       "         9.9827e-01,  4.4069e-03,  2.5105e-01,  7.3210e-03, -4.6245e-02,\n",
       "         3.4716e-02, -6.9202e-01,  9.9732e-01, -6.7538e-01, -4.6917e-02,\n",
       "        -1.9063e-02,  4.5733e-01,  2.6150e-02, -3.5224e-02,  1.0000e+00,\n",
       "         1.0802e-01, -9.4672e-01, -2.4880e-02,  5.0121e-02, -4.1251e-02,\n",
       "        -8.3262e-01,  7.5446e-04,  4.4209e-02,  9.9611e-01,  1.0000e+00,\n",
       "         1.8144e-02, -3.1721e-02,  8.2908e-03,  6.3371e-02, -1.4744e-01,\n",
       "         5.0990e-02,  1.2859e-02, -2.8733e-02,  3.2246e-02, -3.8798e-02,\n",
       "         2.1359e-02, -8.5087e-01,  3.9074e-02,  6.3133e-02, -2.9530e-02,\n",
       "        -9.0109e-03, -5.5240e-02, -9.9616e-01,  2.3404e-01, -9.8977e-01,\n",
       "         4.8511e-02, -2.1278e-03,  9.2124e-03,  8.8052e-02,  9.9594e-01,\n",
       "        -3.3783e-03, -1.0881e-02,  9.6262e-01,  7.5792e-03, -7.8723e-01,\n",
       "        -1.0000e+00, -2.8740e-02,  9.4328e-01, -6.7068e-03, -3.1938e-03,\n",
       "        -5.1636e-02,  4.2444e-02, -5.8322e-01,  1.4482e-02,  6.6845e-02,\n",
       "         2.1021e-04, -9.4583e-01,  1.0000e+00,  2.2275e-03, -7.1274e-02,\n",
       "        -1.5471e-02,  5.6248e-02, -9.0303e-01, -9.8511e-01,  2.4758e-02,\n",
       "         5.3385e-02, -9.9676e-01,  4.8110e-02,  5.1663e-02,  3.4001e-02,\n",
       "        -3.5872e-01,  5.3364e-02, -8.0770e-02,  1.9101e-02, -2.5193e-02,\n",
       "         4.0370e-02, -9.4875e-01,  8.6556e-01, -7.4989e-02,  3.0147e-02,\n",
       "        -1.0000e+00,  2.5803e-02,  9.9854e-01,  2.6380e-01,  2.2321e-02,\n",
       "        -9.1328e-04,  6.3377e-02, -2.3042e-03, -9.1928e-03, -4.6147e-03,\n",
       "        -8.5375e-01,  1.0000e+00, -7.0432e-01, -2.6842e-02,  2.6163e-02,\n",
       "        -5.5625e-01, -4.4880e-03, -4.1386e-02, -6.7953e-03,  2.5081e-03,\n",
       "         3.0903e-02, -4.1841e-02,  9.0816e-04,  4.3477e-01, -6.5036e-01,\n",
       "         9.9915e-01, -7.1797e-01,  7.2748e-03, -7.5331e-01, -5.3599e-02,\n",
       "        -6.8563e-04, -9.9990e-01, -6.5422e-01,  1.4532e-02, -4.5724e-02,\n",
       "        -8.5585e-01,  4.0268e-03, -2.3069e-02, -5.4680e-03, -1.0226e-02,\n",
       "         4.8845e-02, -5.9501e-01,  1.4714e-02, -7.7439e-01,  3.4787e-01,\n",
       "         1.3900e-02, -1.7407e-02, -8.9917e-01, -1.2984e-02, -4.6581e-02,\n",
       "        -8.2804e-01,  7.1064e-03, -9.3168e-01, -9.4514e-01, -6.5427e-01,\n",
       "         4.1950e-02,  9.6348e-01, -3.1957e-01,  4.0882e-01,  9.6946e-01,\n",
       "         9.0043e-01, -5.2949e-02,  1.1958e-02,  1.0000e+00, -8.6099e-01,\n",
       "         2.8337e-02,  1.1053e-02,  7.2799e-01,  7.7648e-01, -1.7699e-03,\n",
       "        -9.7333e-01,  3.7710e-02, -4.8818e-01, -3.0119e-02, -2.3663e-02,\n",
       "        -3.7869e-01, -2.7020e-02, -5.5030e-01,  5.9783e-03,  6.7391e-01,\n",
       "         3.9402e-02, -4.0922e-02, -5.7528e-02,  1.0235e-01,  2.8448e-02,\n",
       "         9.9515e-01,  7.1818e-02, -9.9446e-01, -4.8008e-02, -9.9017e-01,\n",
       "        -1.6901e-02,  6.1574e-02,  3.2904e-02,  8.7109e-01,  1.6927e-02,\n",
       "        -5.6661e-01, -2.0825e-02, -1.0054e-02,  5.9551e-01,  1.5596e-01,\n",
       "        -1.0000e+00, -9.9119e-01, -4.1477e-01,  1.2085e-03,  2.5314e-01,\n",
       "        -9.8248e-01,  3.7297e-02,  4.3309e-02,  1.1758e-01, -1.0000e+00,\n",
       "         2.4662e-02, -6.8431e-02, -5.5098e-02, -3.3890e-02, -9.9364e-01,\n",
       "         1.0489e-02,  8.9181e-01, -1.6932e-02, -5.1336e-02, -6.4697e-01,\n",
       "        -9.9982e-01,  3.6908e-02, -2.2739e-02, -9.2198e-01, -1.7027e-02,\n",
       "         7.2516e-01,  2.4213e-02, -9.7556e-01,  9.9936e-01, -3.9739e-02,\n",
       "        -2.9608e-02, -8.2070e-01, -7.3517e-02, -6.2865e-01, -8.1093e-01,\n",
       "         9.5124e-01, -4.3791e-02,  1.7971e-02,  3.5809e-03, -6.6581e-02,\n",
       "        -4.0983e-02, -2.9327e-02,  3.7672e-02, -9.5908e-01, -3.5173e-02,\n",
       "         5.1071e-01,  2.2185e-02, -1.8315e-02,  8.7221e-03,  1.0897e-02,\n",
       "        -7.9962e-01, -1.7901e-02, -9.9979e-01,  4.4615e-02,  9.8816e-01,\n",
       "        -7.8376e-02, -4.4667e-02, -9.2566e-03, -5.5528e-03, -1.0000e+00,\n",
       "        -2.9701e-02, -1.0000e+00,  6.7681e-02,  8.0726e-01, -2.1498e-02,\n",
       "         2.7569e-03,  9.2036e-02,  1.0575e-02, -9.3903e-01, -9.4951e-01,\n",
       "         1.4128e-02, -1.0000e+00, -9.9970e-01, -9.3716e-01, -4.3265e-02,\n",
       "         8.0154e-01, -4.7511e-02,  9.2477e-01,  3.1897e-02,  7.6033e-02,\n",
       "        -5.2695e-01,  3.0003e-02,  7.8454e-04, -7.4730e-02, -9.7698e-01,\n",
       "        -9.2154e-03,  2.3691e-02,  3.4781e-02,  1.0704e-02, -4.1415e-01,\n",
       "        -4.9134e-02,  5.0517e-02,  1.3540e-02, -9.4824e-01,  4.7129e-02,\n",
       "         1.7691e-02, -1.2300e-02, -1.3341e-01,  5.9825e-03, -1.0875e-01,\n",
       "         5.3458e-03, -9.8539e-01,  4.0970e-02,  3.3741e-03,  8.7862e-01,\n",
       "        -2.2057e-02, -7.6748e-03, -9.9683e-01, -1.0113e-02,  9.1612e-01,\n",
       "         9.4445e-01,  9.2646e-01,  9.9970e-01,  1.0150e-01,  8.7922e-01,\n",
       "         4.9184e-02, -9.6516e-01, -1.7939e-02,  9.7337e-01,  7.4240e-02,\n",
       "         3.5078e-02, -3.5844e-02, -9.9261e-01, -4.1791e-02, -1.0000e+00,\n",
       "        -6.5847e-02, -6.2380e-01, -9.2534e-01, -4.4835e-02, -4.1949e-02,\n",
       "        -9.3882e-01, -7.9219e-01, -6.6931e-02, -1.3348e-02,  5.8676e-02,\n",
       "         8.3550e-02, -9.9567e-03, -9.9424e-01,  5.3816e-02,  9.4891e-01,\n",
       "        -7.7183e-02, -6.0195e-02, -5.3639e-03,  1.9023e-02, -3.9255e-02,\n",
       "        -2.9911e-02,  7.9529e-03,  6.9558e-01,  9.5131e-01, -4.7293e-01,\n",
       "         9.7235e-01,  2.6728e-02, -8.1778e-01,  2.5978e-02,  2.5210e-02,\n",
       "        -4.9689e-02,  9.9039e-01, -7.9214e-02,  1.0000e+00,  9.8058e-01,\n",
       "        -9.9641e-01,  8.1403e-01, -4.2500e-02,  9.0800e-01, -6.0028e-02,\n",
       "        -9.8169e-01, -2.0031e-02, -9.7884e-01,  2.6269e-02, -1.6539e-02,\n",
       "         2.5321e-02, -8.4615e-01, -9.9998e-01,  1.3305e-02, -1.4713e-01,\n",
       "        -5.5964e-02, -9.3782e-01,  6.3045e-02, -1.0000e+00,  7.6617e-02,\n",
       "         8.9675e-01,  9.9058e-01, -3.9372e-02,  1.8188e-02,  9.9677e-01,\n",
       "         4.9736e-03, -7.7605e-01, -2.8975e-02,  7.4025e-02,  2.0305e-02,\n",
       "        -9.9679e-01,  2.5871e-02,  1.0699e-01, -2.6010e-02,  3.5201e-02,\n",
       "        -5.1290e-02, -3.5860e-02,  9.4697e-01, -1.1747e-01, -3.8124e-02,\n",
       "        -9.5861e-03,  9.6168e-01,  1.8856e-02,  2.6576e-02,  3.2589e-02,\n",
       "        -9.0654e-01,  2.4332e-02,  1.0000e+00,  7.3389e-01,  9.9108e-01,\n",
       "         9.9436e-01, -1.7526e-02,  3.5007e-03,  9.9364e-01,  3.2383e-01,\n",
       "        -1.7819e-02, -8.1269e-02, -9.9691e-01, -5.2430e-02,  5.8706e-01,\n",
       "         8.8377e-01,  8.3309e-01, -1.0000e+00,  4.5864e-02,  9.9683e-01,\n",
       "         9.8773e-01, -9.2864e-01,  9.9038e-01, -9.8523e-01, -9.1492e-01,\n",
       "        -4.2439e-02,  2.5461e-02, -3.3165e-01,  2.1902e-02,  2.5899e-03,\n",
       "         1.0000e+00, -4.3524e-02,  4.9362e-03,  1.4651e-01, -1.2598e-02,\n",
       "        -8.2295e-02, -4.7689e-03,  4.4542e-02,  9.9451e-01,  3.7600e-02,\n",
       "         4.1944e-02,  9.9699e-03, -1.0000e+00, -5.0011e-01,  1.0554e-01,\n",
       "         3.1391e-02,  9.4445e-03, -9.9687e-01, -4.3980e-02, -6.0468e-02,\n",
       "        -4.3254e-03, -6.6276e-01,  1.2961e-02,  1.6739e-02,  5.2487e-01,\n",
       "        -1.9420e-02,  1.9941e-02,  1.2221e-02, -6.2974e-02, -3.2875e-02,\n",
       "         9.7473e-01, -8.9447e-01,  3.8239e-02,  2.6936e-01,  9.9795e-01,\n",
       "         1.9770e-02, -2.2550e-02, -8.7961e-01, -9.9463e-01, -8.7241e-01,\n",
       "         9.9858e-01, -3.5364e-02, -1.8619e-01, -2.9592e-02, -8.9382e-01,\n",
       "         3.6497e-02,  9.9453e-01, -9.1353e-01,  2.8639e-02, -9.9998e-01,\n",
       "        -7.1643e-03,  1.8039e-02,  2.5152e-02], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.pooler_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "807fa55daafc4dd55299ec469926b2dbf7abbf01492f4cb45e7d3fd3e08c883b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
