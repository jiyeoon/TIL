# ****Temporal Fusion Transformer: Time Series Forecasting with Deep Learning — Complete Tutorial****

### Temporal Fusion Transformer (TFT)란

- **self-attention을 활용**해 여러 시간 시퀀스의 복잡한 시간 역학을 캡쳐하는 transformer 기반 모델
- 다중 시계열 : 수천개의 단변량 혹은 다변량 시계열에서 tft 모델을 학습할 수 있다.
- multi-horizon forecasting : 하나 이상의 대상 변수에 대한 다단계 예측을 출력
- 이기종 기능 (?) : 시변 및 정적 외생 변수를 포함해 다양한 유형의 기능 지원
- 해석 가능한 예측 : 변수 중요도 및 계절성 측면에서 예측 해석할 수 있음.

### TFT의 확장된 데이터 포맷

- 기존 다른 DL기반 시계열 예측 모델들과 달리 여기선 4가지 타입의 피처를 제공?지원함.
- 종류
    - time-varying *known*
    - time-varing *unknown*
    - time-invariant *real*
    - time-invariant *categorical*
- 예를들어 판매량을 예측한다고 생각해보자.
    - 주문수 : target variable
    - CPI index나 방문자수 : time-varying unknown feature
    - holiday, weekends : time varying known 이벤트
    - product_id : time-invariant(static) categorical feature
    - yearly_revenue : time-invariant real

### 예시 샘플 데이터와 코드

1. Data Preprocessing
    1. 타겟 데이터는 `power_usage` 
    2. 새로운 피처로 `month` , `day` , `hour` , `day_of_week` 를 생성
    3. 기간은 2014-01-01 부터 2014-09-07로 설정
    4. 그 외 데이터는 customer_id 등이 있당.
2. EDA
3. Create DataLoader
    1. time_df 불러온 것을 `TimeSeriesDataSet` 포맷에 넣어줌.
        1. 자체 Dataloader를 설정하지 않아도 됨
        2. TFT가 데이터 세트의 기능을 처리하는 방법일 지정할 수 있음.
        3. 데이터세트를 쉽게 정규화할 수 있음. (`GroupNormalizer` 를 사용해서 각 시계열을 개별적으로 정규화)
4. Baseline model
    1. 기본 모델. naive한 모델보다 더 나은지 기준 모델 생성하기.
5. Temporal Fusion Transformer 학습
    1. **pytorch Lightning의 `Trainer` 인터페이스를 사용해 훈련 가능**
    2. EarlyStopping 콜백을 사용해 유효성 검사 손실을 모니터링
    3. Tensorboard를 사용해 교육 및 검증 매트릭 기록
    4. Quantile Loss를 사용 : 예측 간격을 출력하는데 도움이 되는 특수한 손실 함수..
    5. 기존 논문에 있던데로 4개의 어텐션 헤드를 사용할거임.